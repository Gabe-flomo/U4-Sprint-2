{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "a function that can revieve and send information. When working with other neurons, they can make predictions\n",
    "\n",
    "- **Input Layer:**\n",
    "The first layer of a neural network where the flow of data begins and is feed forward for processing by other layers.\n",
    "\n",
    "- **Hidden Layer:**\n",
    "an intermediate layer that calculates weighted sums and is feed forward towards the output.\n",
    "- **Output Layer:**\n",
    "After the data is processed, this layer calculates the final results.\n",
    "- **Activation:**\n",
    "A function that decides how much a neuron contributes to the network based on its weighted sum.\n",
    "- **Backpropagation:**\n",
    "An algorithm that determines what weights were most responsible for causing som error in the output and uses gradient descent or some other type of optimization function to minimize the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(812)\n",
    "\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. You will not be able to achieve more than ~50% with the simple perceptron. Explain why you could not achieve a higher accuracy with the *simple perceptron* architecture, because it's possible to achieve ~95% accuracy on this dataset. Provide your answer in markdown (and *optional* data anlysis code) after your perceptron implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derv(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x1 matrix for weights since there are 2 inputs and one output\n",
    "weights = 2 * np.random.random((2,1)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: \n",
      " [[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "Wall time: 54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    #weighted sum\n",
    "    weighted_sum = np.dot(X,weights)\n",
    "    \n",
    "    #activate \n",
    "    activate = sigmoid(weighted_sum)\n",
    "    \n",
    "    #calculate error\n",
    "    error = y - activate\n",
    "    \n",
    "    #adjust weights\n",
    "    adj = error * sigmoid_derv(activate)\n",
    "    \n",
    "    # update weights \n",
    "    weights = weights + np.dot(X.T,adj)\n",
    "\n",
    "print(f\"Output: \\n {activate}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: \n",
      " 0.9370499999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy: \\n {1-(np.mean(np.square(y-activate)))}\") # mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.inputs = 2\n",
    "        self.hidden = 4\n",
    "        self.output = 1\n",
    "        \n",
    "        self.weight1 = np.random.rand(self.inputs,self.hidden)\n",
    "        self.weight2 = np.random.rand(self.hidden,self.output)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def sigprime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def fforward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # calculate the weighted sum of inputs => hidden layer\n",
    "        # the dot product is established by multiplying each component\n",
    "        # in one vector by each component in another vector, then add all the products\n",
    "        # a = [2,3,4] \n",
    "        # b = [5,6,7]\n",
    "        # dotproduct = (2*5) + (3*6) + (4*7) == 56\n",
    "        self.hidden_sum = np.dot(X, self.weight1)\n",
    "        \n",
    "        # Activation of hidden sum\n",
    "        self.hidden_activation = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # calculate the weighted sum of hidden layer => output\n",
    "        self.output_sum = np.dot(self.hidden_activation,self.weight2)\n",
    "        \n",
    "        #final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "    \n",
    "    \n",
    "    def backprop(self,X,y,o):\n",
    "        \n",
    "        # calculate output error\n",
    "        self.oerror = y - o\n",
    "        \n",
    "        # Apply Derivative of Sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- aka hidden => output\n",
    "        self.odelta = self.oerror * self.sigprime(o)\n",
    "        \n",
    "        \n",
    "        # z2 error \n",
    "        self.error_z2 = self.odelta.dot(self.weight2.T)\n",
    "        # How much of that \"far off\" can explained by the input => hidden\n",
    "        self.delta_z2 = self.error_z2 * self.sigprime(self.hidden_activation)\n",
    "        \n",
    "        # adjusting the weights from input => hidden\n",
    "        self.weight1 = self.weight1 + X.T.dot(self.delta_z2)\n",
    "        \n",
    "        # adjusting the weights from hidden => output\n",
    "        self.weight2 = self.weight2 + self.hidden_activation.T.dot(self.odelta)\n",
    "        \n",
    "        \n",
    "    def train(self, X,y):\n",
    "        o = self.fforward(X)\n",
    "        print(f\"shapes: O {o.shape},X: {X.shape}, Y: {y.shape}\")\n",
    "        self.backprop(X,y,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: O (10000, 1),X: (10000, 2), Y: (10000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10000,10000) and (1,4) not aligned: 10000 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-1692e601a41c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Actual: \\n {y}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-d5623c47c991>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"shapes: O {o.shape},X: {X.shape}, Y: {y.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-d5623c47c991>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, X, y, o)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# z2 error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_z2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0modelta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;31m# How much of that \"far off\" can explained by the input => hidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta_z2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_z2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_activation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10000,10000) and (1,4) not aligned: 10000 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "\n",
    "for i in range(100):\n",
    "    nn.train(X,y)\n",
    "\n",
    "print(f\"Actual: \\n {y}\")\n",
    "print(f\"Prediction: \\n {nn.fforward(X)}\")\n",
    "print(f\"accuracy: \\n {1-(np.mean(np.square(y-nn.fforward(X))))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "93    54    0   1       132   288    1        0      159      1      0.0   \n",
       "181   65    0   0       150   225    0        0      114      0      1.0   \n",
       "118   46    0   1       105   204    0        1      172      0      0.0   \n",
       "124   39    0   2        94   199    0        1      179      0      0.0   \n",
       "179   57    1   0       150   276    0        0      112      1      0.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "93       2   1     2       1  \n",
       "181      1   3     3       0  \n",
       "118      2   0     2       1  \n",
       "124      2   0     2       1  \n",
       "179      1   1     1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']].values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(2,input_dim = 13,activation = 'relu'))\n",
    "model.add(Dense(4,activation = 'sigmoid'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/250\n",
      "303/303 [==============================] - 2s 5ms/sample - loss: 0.7246 - accuracy: 0.5446\n",
      "Epoch 2/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.7206 - accuracy: 0.5446\n",
      "Epoch 3/250\n",
      "303/303 [==============================] - 0s 66us/sample - loss: 0.7168 - accuracy: 0.5446\n",
      "Epoch 4/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7143 - accuracy: 0.5446\n",
      "Epoch 5/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7119 - accuracy: 0.5446\n",
      "Epoch 6/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7098 - accuracy: 0.5446\n",
      "Epoch 7/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7079 - accuracy: 0.5446\n",
      "Epoch 8/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.7059 - accuracy: 0.5446\n",
      "Epoch 9/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.7044 - accuracy: 0.5446\n",
      "Epoch 10/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.7028 - accuracy: 0.5446\n",
      "Epoch 11/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.7015 - accuracy: 0.5446\n",
      "Epoch 12/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.7005 - accuracy: 0.5446\n",
      "Epoch 13/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6992 - accuracy: 0.5446\n",
      "Epoch 14/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6985 - accuracy: 0.5446\n",
      "Epoch 15/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6976 - accuracy: 0.5446\n",
      "Epoch 16/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6969 - accuracy: 0.5446\n",
      "Epoch 17/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6965 - accuracy: 0.5446\n",
      "Epoch 18/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6957 - accuracy: 0.5446\n",
      "Epoch 19/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6949 - accuracy: 0.5446\n",
      "Epoch 20/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.6945 - accuracy: 0.5446\n",
      "Epoch 21/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6937 - accuracy: 0.5446\n",
      "Epoch 22/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6935 - accuracy: 0.5446\n",
      "Epoch 23/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6931 - accuracy: 0.5446\n",
      "Epoch 24/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6926 - accuracy: 0.5446\n",
      "Epoch 25/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6924 - accuracy: 0.5446\n",
      "Epoch 26/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6922 - accuracy: 0.5446\n",
      "Epoch 27/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6919 - accuracy: 0.5446\n",
      "Epoch 28/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6916 - accuracy: 0.5446\n",
      "Epoch 29/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6914 - accuracy: 0.5446\n",
      "Epoch 30/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6914 - accuracy: 0.5446\n",
      "Epoch 31/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6910 - accuracy: 0.5446\n",
      "Epoch 32/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6909 - accuracy: 0.5446\n",
      "Epoch 33/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6908 - accuracy: 0.5446\n",
      "Epoch 34/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6905 - accuracy: 0.5446\n",
      "Epoch 35/250\n",
      "303/303 [==============================] - 0s 47us/sample - loss: 0.6906 - accuracy: 0.5446\n",
      "Epoch 36/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6905 - accuracy: 0.5446\n",
      "Epoch 37/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6903 - accuracy: 0.5446\n",
      "Epoch 38/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6903 - accuracy: 0.5446\n",
      "Epoch 39/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6902 - accuracy: 0.5446\n",
      "Epoch 40/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6902 - accuracy: 0.5446\n",
      "Epoch 41/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6902 - accuracy: 0.5446\n",
      "Epoch 42/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6900 - accuracy: 0.5446\n",
      "Epoch 43/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6901 - accuracy: 0.5446\n",
      "Epoch 44/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6900 - accuracy: 0.5446\n",
      "Epoch 45/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6900 - accuracy: 0.5446\n",
      "Epoch 46/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6899 - accuracy: 0.5446\n",
      "Epoch 47/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6899 - accuracy: 0.5446\n",
      "Epoch 48/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6899 - accuracy: 0.5446\n",
      "Epoch 49/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6899 - accuracy: 0.5446\n",
      "Epoch 50/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6899 - accuracy: 0.5446\n",
      "Epoch 51/250\n",
      "303/303 [==============================] - 0s 38us/sample - loss: 0.6898 - accuracy: 0.5446\n",
      "Epoch 52/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6898 - accuracy: 0.5446\n",
      "Epoch 53/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6898 - accuracy: 0.5446\n",
      "Epoch 54/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 55/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 56/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 57/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6898 - accuracy: 0.5446\n",
      "Epoch 58/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 59/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 60/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 61/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 62/250\n",
      "303/303 [==============================] - 0s 79us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 63/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 64/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 65/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 66/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 67/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 68/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 69/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 70/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 71/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 72/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 73/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 74/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 75/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 76/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 77/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 78/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 79/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 80/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 81/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 82/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 83/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 84/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 85/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 86/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 87/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 88/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 89/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 90/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 91/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 92/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 93/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6893 - accuracy: 0.5446\n",
      "Epoch 94/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 95/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 96/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 97/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 98/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 99/250\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 100/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 101/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 102/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 103/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 104/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 105/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 106/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 107/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 108/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 109/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 110/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 111/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 112/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6892 - accuracy: 0.5446\n",
      "Epoch 113/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 114/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 115/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 116/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 117/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 118/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 119/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 120/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 121/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 122/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 123/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 124/250\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.59 - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 125/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 126/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 127/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 128/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 129/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 130/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 131/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 132/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 133/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 134/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 135/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 136/250\n",
      "303/303 [==============================] - 0s 37us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 137/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 138/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 139/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6890 - accuracy: 0.5446\n",
      "Epoch 140/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 141/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 142/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 143/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 144/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 145/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 146/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 147/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 148/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 149/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 150/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 151/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 152/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 153/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 154/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 155/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 156/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 157/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 158/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 159/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 160/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 161/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 162/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 163/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 164/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 165/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 166/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 167/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 168/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 169/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 170/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 171/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 172/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 173/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 174/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 175/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 176/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 177/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 178/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 179/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 180/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 181/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 182/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 183/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 184/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 185/250\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 186/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 187/250\n",
      "303/303 [==============================] - 0s 48us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 188/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6888 - accuracy: 0.5446\n",
      "Epoch 189/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 190/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 191/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 192/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 193/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 194/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 195/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 196/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 197/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 198/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 199/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 200/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 201/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 202/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 203/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 204/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 205/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 206/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 207/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 208/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 209/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 210/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 211/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 212/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 213/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 214/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 215/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 216/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 217/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 218/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 219/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 220/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 221/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 222/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 223/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 224/250\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 225/250\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 226/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 227/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 228/250\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 229/250\n",
      "303/303 [==============================] - 0s 76us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 230/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6882 - accuracy: 0.5446\n",
      "Epoch 231/250\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6885 - accuracy: 0.5446\n",
      "Epoch 232/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 233/250\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 234/250\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.6882 - accuracy: 0.5446\n",
      "Epoch 235/250\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 236/250\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 237/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 238/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 239/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 240/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6884 - accuracy: 0.5446\n",
      "Epoch 241/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6882 - accuracy: 0.5446\n",
      "Epoch 242/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6886 - accuracy: 0.5446\n",
      "Epoch 243/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6881 - accuracy: 0.5446\n",
      "Epoch 244/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6889 - accuracy: 0.5446\n",
      "Epoch 245/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 246/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6882 - accuracy: 0.5446\n",
      "Epoch 247/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6882 - accuracy: 0.5446\n",
      "Epoch 248/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 249/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 250/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6882 - accuracy: 0.5446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20948a444e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs = 250, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 54.45544719696045\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X,y,verbose = False)\n",
    "print(f\"{model.metrics_names[1]}: {score[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline accuracy of 54%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/75\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.7445 - accuracy: 0.5446\n",
      "Epoch 2/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7394 - accuracy: 0.5446\n",
      "Epoch 3/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7359 - accuracy: 0.5446\n",
      "Epoch 4/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7327 - accuracy: 0.5446\n",
      "Epoch 5/75\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7295 - accuracy: 0.5446\n",
      "Epoch 6/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7263 - accuracy: 0.5446\n",
      "Epoch 7/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7235 - accuracy: 0.5446\n",
      "Epoch 8/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7208 - accuracy: 0.5446\n",
      "Epoch 9/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7181 - accuracy: 0.5446\n",
      "Epoch 10/75\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7156 - accuracy: 0.5446\n",
      "Epoch 11/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7135 - accuracy: 0.5446\n",
      "Epoch 12/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7115 - accuracy: 0.5446\n",
      "Epoch 13/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7096 - accuracy: 0.5446\n",
      "Epoch 14/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7079 - accuracy: 0.5446\n",
      "Epoch 15/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7065 - accuracy: 0.5446\n",
      "Epoch 16/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.7055 - accuracy: 0.5446\n",
      "Epoch 17/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7042 - accuracy: 0.5446\n",
      "Epoch 18/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7025 - accuracy: 0.5446\n",
      "Epoch 19/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7012 - accuracy: 0.5446\n",
      "Epoch 20/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7004 - accuracy: 0.5446\n",
      "Epoch 21/75\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6992 - accuracy: 0.5446\n",
      "Epoch 22/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6980 - accuracy: 0.5446\n",
      "Epoch 23/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6970 - accuracy: 0.5446\n",
      "Epoch 24/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6960 - accuracy: 0.5446\n",
      "Epoch 25/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6951 - accuracy: 0.5446\n",
      "Epoch 26/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6943 - accuracy: 0.5446\n",
      "Epoch 27/75\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6933 - accuracy: 0.5446\n",
      "Epoch 28/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6923 - accuracy: 0.5446\n",
      "Epoch 29/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6927 - accuracy: 0.5446\n",
      "Epoch 30/75\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6928 - accuracy: 0.5446\n",
      "Epoch 31/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6920 - accuracy: 0.5446\n",
      "Epoch 32/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6903 - accuracy: 0.5446\n",
      "Epoch 33/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6908 - accuracy: 0.5446\n",
      "Epoch 34/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6915 - accuracy: 0.5446\n",
      "Epoch 35/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6912 - accuracy: 0.5446\n",
      "Epoch 36/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6901 - accuracy: 0.5446\n",
      "Epoch 37/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 38/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6896 - accuracy: 0.5446\n",
      "Epoch 39/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6891 - accuracy: 0.5446\n",
      "Epoch 40/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6887 - accuracy: 0.5446\n",
      "Epoch 41/75\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 42/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6883 - accuracy: 0.5446\n",
      "Epoch 43/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6882 - accuracy: 0.5446\n",
      "Epoch 44/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6878 - accuracy: 0.5446\n",
      "Epoch 45/75\n",
      "303/303 [==============================] - 0s 69us/sample - loss: 0.6877 - accuracy: 0.5446\n",
      "Epoch 46/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6874 - accuracy: 0.5446\n",
      "Epoch 47/75\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6870 - accuracy: 0.5446\n",
      "Epoch 48/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6870 - accuracy: 0.5446\n",
      "Epoch 49/75\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6871 - accuracy: 0.5446\n",
      "Epoch 50/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6868 - accuracy: 0.5446\n",
      "Epoch 51/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6866 - accuracy: 0.5446\n",
      "Epoch 52/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6866 - accuracy: 0.5446\n",
      "Epoch 53/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6864 - accuracy: 0.5446\n",
      "Epoch 54/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6865 - accuracy: 0.5446\n",
      "Epoch 55/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6863 - accuracy: 0.5446\n",
      "Epoch 56/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6859 - accuracy: 0.5446\n",
      "Epoch 57/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6858 - accuracy: 0.5446\n",
      "Epoch 58/75\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6860 - accuracy: 0.5446\n",
      "Epoch 59/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6859 - accuracy: 0.5446\n",
      "Epoch 60/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6857 - accuracy: 0.5446\n",
      "Epoch 61/75\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.52 - 0s 39us/sample - loss: 0.6856 - accuracy: 0.5446\n",
      "Epoch 62/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6858 - accuracy: 0.5446\n",
      "Epoch 63/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6858 - accuracy: 0.5446\n",
      "Epoch 64/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6856 - accuracy: 0.5446\n",
      "Epoch 65/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6855 - accuracy: 0.5446\n",
      "Epoch 66/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6855 - accuracy: 0.5446\n",
      "Epoch 67/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6854 - accuracy: 0.5446\n",
      "Epoch 68/75\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6854 - accuracy: 0.5446\n",
      "Epoch 69/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6853 - accuracy: 0.5446\n",
      "Epoch 70/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6853 - accuracy: 0.5446\n",
      "Epoch 71/75\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6854 - accuracy: 0.5446\n",
      "Epoch 72/75\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6853 - accuracy: 0.5446\n",
      "Epoch 73/75\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6853 - accuracy: 0.5446\n",
      "Epoch 74/75\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6848 - accuracy: 0.5446\n",
      "Epoch 75/75\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6853 - accuracy: 0.5446\n",
      "Best: 0.5808580815792084 using {'batch_size': 50, 'epochs': 75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def create():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2,input_dim = 13,activation = 'relu'))\n",
    "    model.add(Dense(4,activation = 'sigmoid'))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model2 = KerasClassifier(build_fn = create)\n",
    "\n",
    "parameters = {'batch_size': [10,20,50,80,100],\n",
    "             'epochs':[75]}\n",
    "\n",
    "grid = GridSearchCV(estimator = model2, param_grid = parameters, n_jobs = -1)\n",
    "results = grid.fit(X,y)\n",
    "\n",
    "# report best \n",
    "print(f\"Best: {results.best_score_} using {results.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best with batch_size of 50 and 75 epochs\n",
    "# accuracy 58%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/200\n",
      "303/303 [==============================] - 1s 2ms/sample - loss: 0.6904 - accuracy: 0.5446\n",
      "Epoch 2/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6897 - accuracy: 0.5446\n",
      "Epoch 3/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6895 - accuracy: 0.5446\n",
      "Epoch 4/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6883 - accuracy: 0.5479\n",
      "Epoch 5/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6877 - accuracy: 0.5611\n",
      "Epoch 6/200\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6876 - accuracy: 0.5578\n",
      "Epoch 7/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6872 - accuracy: 0.5611\n",
      "Epoch 8/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6869 - accuracy: 0.5677\n",
      "Epoch 9/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6871 - accuracy: 0.5743\n",
      "Epoch 10/200\n",
      "303/303 [==============================] - 0s 41us/sample - loss: 0.6873 - accuracy: 0.5644\n",
      "Epoch 11/200\n",
      "303/303 [==============================] - 0s 41us/sample - loss: 0.6870 - accuracy: 0.5677\n",
      "Epoch 12/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6867 - accuracy: 0.5710\n",
      "Epoch 13/200\n",
      "303/303 [==============================] - 0s 56us/sample - loss: 0.6861 - accuracy: 0.5677\n",
      "Epoch 14/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6858 - accuracy: 0.5743\n",
      "Epoch 15/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6855 - accuracy: 0.5743\n",
      "Epoch 16/200\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6852 - accuracy: 0.5743\n",
      "Epoch 17/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6849 - accuracy: 0.5743\n",
      "Epoch 18/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6844 - accuracy: 0.5776\n",
      "Epoch 19/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6840 - accuracy: 0.5809\n",
      "Epoch 20/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6830 - accuracy: 0.5842\n",
      "Epoch 21/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6820 - accuracy: 0.5875\n",
      "Epoch 22/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6800 - accuracy: 0.5974\n",
      "Epoch 23/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6758 - accuracy: 0.6370\n",
      "Epoch 24/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6756 - accuracy: 0.6337\n",
      "Epoch 25/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6745 - accuracy: 0.6436\n",
      "Epoch 26/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6740 - accuracy: 0.6403\n",
      "Epoch 27/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6736 - accuracy: 0.6370\n",
      "Epoch 28/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6732 - accuracy: 0.6370\n",
      "Epoch 29/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6729 - accuracy: 0.6436\n",
      "Epoch 30/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6728 - accuracy: 0.6436\n",
      "Epoch 31/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6726 - accuracy: 0.6436\n",
      "Epoch 32/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6739 - accuracy: 0.6304\n",
      "Epoch 33/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6749 - accuracy: 0.6271\n",
      "Epoch 34/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6741 - accuracy: 0.6271\n",
      "Epoch 35/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6722 - accuracy: 0.6337\n",
      "Epoch 36/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6718 - accuracy: 0.6370\n",
      "Epoch 37/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6708 - accuracy: 0.6403\n",
      "Epoch 38/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6703 - accuracy: 0.6469\n",
      "Epoch 39/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6700 - accuracy: 0.6436\n",
      "Epoch 40/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6695 - accuracy: 0.6436\n",
      "Epoch 41/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6690 - accuracy: 0.6436\n",
      "Epoch 42/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6687 - accuracy: 0.6469\n",
      "Epoch 43/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6682 - accuracy: 0.6469\n",
      "Epoch 44/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6699 - accuracy: 0.6304\n",
      "Epoch 45/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6717 - accuracy: 0.6172\n",
      "Epoch 46/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6679 - accuracy: 0.6403\n",
      "Epoch 47/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6681 - accuracy: 0.6337\n",
      "Epoch 48/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6672 - accuracy: 0.6403\n",
      "Epoch 49/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6666 - accuracy: 0.6436\n",
      "Epoch 50/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6660 - accuracy: 0.6436\n",
      "Epoch 51/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6662 - accuracy: 0.6436\n",
      "Epoch 52/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6656 - accuracy: 0.6436\n",
      "Epoch 53/200\n",
      "303/303 [==============================] - 0s 79us/sample - loss: 0.6678 - accuracy: 0.6238\n",
      "Epoch 54/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6660 - accuracy: 0.6370\n",
      "Epoch 55/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6643 - accuracy: 0.6502\n",
      "Epoch 56/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6644 - accuracy: 0.6436\n",
      "Epoch 57/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6640 - accuracy: 0.6502\n",
      "Epoch 58/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6636 - accuracy: 0.6469\n",
      "Epoch 59/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6632 - accuracy: 0.6502\n",
      "Epoch 60/200\n",
      "303/303 [==============================] - 0s 47us/sample - loss: 0.6628 - accuracy: 0.6502\n",
      "Epoch 61/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6625 - accuracy: 0.6502\n",
      "Epoch 62/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6622 - accuracy: 0.6502\n",
      "Epoch 63/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6620 - accuracy: 0.6502\n",
      "Epoch 64/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6616 - accuracy: 0.6502\n",
      "Epoch 65/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6616 - accuracy: 0.6469\n",
      "Epoch 66/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6611 - accuracy: 0.6502\n",
      "Epoch 67/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6609 - accuracy: 0.6502\n",
      "Epoch 68/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6604 - accuracy: 0.6502\n",
      "Epoch 69/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6601 - accuracy: 0.6502\n",
      "Epoch 70/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6598 - accuracy: 0.6502\n",
      "Epoch 71/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6605 - accuracy: 0.6370\n",
      "Epoch 72/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6617 - accuracy: 0.6337\n",
      "Epoch 73/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6598 - accuracy: 0.6436\n",
      "Epoch 74/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6589 - accuracy: 0.6502\n",
      "Epoch 75/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6588 - accuracy: 0.6502\n",
      "Epoch 76/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6582 - accuracy: 0.6502\n",
      "Epoch 77/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6584 - accuracy: 0.6403\n",
      "Epoch 78/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6590 - accuracy: 0.6403\n",
      "Epoch 79/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6580 - accuracy: 0.6469\n",
      "Epoch 80/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6569 - accuracy: 0.6502\n",
      "Epoch 81/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6570 - accuracy: 0.6502\n",
      "Epoch 82/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6562 - accuracy: 0.6502\n",
      "Epoch 83/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6574 - accuracy: 0.6370\n",
      "Epoch 84/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6614 - accuracy: 0.6304\n",
      "Epoch 85/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6597 - accuracy: 0.6370\n",
      "Epoch 86/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6566 - accuracy: 0.6469\n",
      "Epoch 87/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6548 - accuracy: 0.6502\n",
      "Epoch 88/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6549 - accuracy: 0.6502\n",
      "Epoch 89/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6542 - accuracy: 0.6502\n",
      "Epoch 90/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6538 - accuracy: 0.6502\n",
      "Epoch 91/200\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6537 - accuracy: 0.6535\n",
      "Epoch 92/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6534 - accuracy: 0.6502\n",
      "Epoch 93/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6539 - accuracy: 0.6502\n",
      "Epoch 94/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6547 - accuracy: 0.6403\n",
      "Epoch 95/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6536 - accuracy: 0.6469\n",
      "Epoch 96/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6520 - accuracy: 0.6403\n",
      "Epoch 97/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6516 - accuracy: 0.6469\n",
      "Epoch 98/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6569 - accuracy: 0.6337\n",
      "Epoch 99/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6610 - accuracy: 0.6139\n",
      "Epoch 100/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6602 - accuracy: 0.6205\n",
      "Epoch 101/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6541 - accuracy: 0.6403\n",
      "Epoch 102/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6500 - accuracy: 0.6502\n",
      "Epoch 103/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6494 - accuracy: 0.6469\n",
      "Epoch 104/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6483 - accuracy: 0.6469\n",
      "Epoch 105/200\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6170 - accuracy: 0.76 - 0s 33us/sample - loss: 0.6493 - accuracy: 0.6469\n",
      "Epoch 106/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6498 - accuracy: 0.6403\n",
      "Epoch 107/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6482 - accuracy: 0.6502\n",
      "Epoch 108/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6479 - accuracy: 0.6568\n",
      "Epoch 109/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6469 - accuracy: 0.6535\n",
      "Epoch 110/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6465 - accuracy: 0.6535\n",
      "Epoch 111/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6462 - accuracy: 0.6535\n",
      "Epoch 112/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6459 - accuracy: 0.6601\n",
      "Epoch 113/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6508 - accuracy: 0.6436\n",
      "Epoch 114/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6476 - accuracy: 0.6502\n",
      "Epoch 115/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6458 - accuracy: 0.6568\n",
      "Epoch 116/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6451 - accuracy: 0.6469\n",
      "Epoch 117/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6451 - accuracy: 0.6502\n",
      "Epoch 118/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6438 - accuracy: 0.6535\n",
      "Epoch 119/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6434 - accuracy: 0.6502\n",
      "Epoch 120/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6432 - accuracy: 0.6469\n",
      "Epoch 121/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6422 - accuracy: 0.6535\n",
      "Epoch 122/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6413 - accuracy: 0.6568\n",
      "Epoch 123/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6448 - accuracy: 0.6436\n",
      "Epoch 124/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6464 - accuracy: 0.6403\n",
      "Epoch 125/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6493 - accuracy: 0.6238\n",
      "Epoch 126/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6485 - accuracy: 0.6304\n",
      "Epoch 127/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6420 - accuracy: 0.6469\n",
      "Epoch 128/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6392 - accuracy: 0.6601\n",
      "Epoch 129/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6388 - accuracy: 0.6469\n",
      "Epoch 130/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6387 - accuracy: 0.6469\n",
      "Epoch 131/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6387 - accuracy: 0.6502\n",
      "Epoch 132/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6388 - accuracy: 0.6568\n",
      "Epoch 133/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6379 - accuracy: 0.6568\n",
      "Epoch 134/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6371 - accuracy: 0.6700\n",
      "Epoch 135/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6365 - accuracy: 0.6667\n",
      "Epoch 136/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6360 - accuracy: 0.6667\n",
      "Epoch 137/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6356 - accuracy: 0.6700\n",
      "Epoch 138/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6357 - accuracy: 0.6634\n",
      "Epoch 139/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6353 - accuracy: 0.6634\n",
      "Epoch 140/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6346 - accuracy: 0.6634\n",
      "Epoch 141/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6354 - accuracy: 0.6667\n",
      "Epoch 142/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6350 - accuracy: 0.6700\n",
      "Epoch 143/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6333 - accuracy: 0.6733\n",
      "Epoch 144/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6329 - accuracy: 0.6700\n",
      "Epoch 145/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6338 - accuracy: 0.6700\n",
      "Epoch 146/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6322 - accuracy: 0.6766\n",
      "Epoch 147/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6317 - accuracy: 0.6700\n",
      "Epoch 148/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6310 - accuracy: 0.6700\n",
      "Epoch 149/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6303 - accuracy: 0.6733\n",
      "Epoch 150/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6317 - accuracy: 0.6667\n",
      "Epoch 151/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6328 - accuracy: 0.6700\n",
      "Epoch 152/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6333 - accuracy: 0.6634\n",
      "Epoch 153/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6302 - accuracy: 0.6733\n",
      "Epoch 154/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6289 - accuracy: 0.6766\n",
      "Epoch 155/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6291 - accuracy: 0.6700\n",
      "Epoch 156/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6299 - accuracy: 0.6700\n",
      "Epoch 157/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6290 - accuracy: 0.6733\n",
      "Epoch 158/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6280 - accuracy: 0.6799\n",
      "Epoch 159/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6280 - accuracy: 0.6766\n",
      "Epoch 160/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6272 - accuracy: 0.6766\n",
      "Epoch 161/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6270 - accuracy: 0.6865\n",
      "Epoch 162/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6259 - accuracy: 0.6799\n",
      "Epoch 163/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6254 - accuracy: 0.6832\n",
      "Epoch 164/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6253 - accuracy: 0.6865\n",
      "Epoch 165/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6250 - accuracy: 0.6832\n",
      "Epoch 166/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6254 - accuracy: 0.6799\n",
      "Epoch 167/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6242 - accuracy: 0.6832\n",
      "Epoch 168/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6237 - accuracy: 0.6865\n",
      "Epoch 169/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6235 - accuracy: 0.6865\n",
      "Epoch 170/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6230 - accuracy: 0.6832\n",
      "Epoch 171/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6235 - accuracy: 0.6766\n",
      "Epoch 172/200\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6232 - accuracy: 0.6766\n",
      "Epoch 173/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6215 - accuracy: 0.6865\n",
      "Epoch 174/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6218 - accuracy: 0.6799\n",
      "Epoch 175/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6222 - accuracy: 0.6799\n",
      "Epoch 176/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6212 - accuracy: 0.6865\n",
      "Epoch 177/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6235 - accuracy: 0.6733\n",
      "Epoch 178/200\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6241 - accuracy: 0.6733\n",
      "Epoch 179/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6221 - accuracy: 0.6733\n",
      "Epoch 180/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6201 - accuracy: 0.6832\n",
      "Epoch 181/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6200 - accuracy: 0.6865\n",
      "Epoch 182/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6195 - accuracy: 0.6832\n",
      "Epoch 183/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6196 - accuracy: 0.6832\n",
      "Epoch 184/200\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6183 - accuracy: 0.6832\n",
      "Epoch 185/200\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6231 - accuracy: 0.6766\n",
      "Epoch 186/200\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6238 - accuracy: 0.6700\n",
      "Epoch 187/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6159 - accuracy: 0.6898\n",
      "Epoch 188/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6201 - accuracy: 0.6766\n",
      "Epoch 189/200\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6241 - accuracy: 0.6634\n",
      "Epoch 190/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6231 - accuracy: 0.6634\n",
      "Epoch 191/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6201 - accuracy: 0.6667\n",
      "Epoch 192/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6154 - accuracy: 0.6898\n",
      "Epoch 193/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6143 - accuracy: 0.6964\n",
      "Epoch 194/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6197 - accuracy: 0.6766\n",
      "Epoch 195/200\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6214 - accuracy: 0.6733\n",
      "Epoch 196/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6178 - accuracy: 0.6997\n",
      "Epoch 197/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6147 - accuracy: 0.6964\n",
      "Epoch 198/200\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6129 - accuracy: 0.6964\n",
      "Epoch 199/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6143 - accuracy: 0.6865\n",
      "Epoch 200/200\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6140 - accuracy: 0.6865\n",
      "Best: 0.6105610529581705 using {'batch_size': 50, 'epochs': 200}\n"
     ]
    }
   ],
   "source": [
    "model2 = KerasClassifier(build_fn = create)\n",
    "\n",
    "parameters = {'batch_size': [50,80,100],\n",
    "             'epochs':[200]}\n",
    "\n",
    "grid = GridSearchCV(estimator = model2, param_grid = parameters, n_jobs = -1)\n",
    "results = grid.fit(X,y)\n",
    "\n",
    "# report best \n",
    "print(f\"Best: {results.best_score_} using {results.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best using batch_size of 50 and 200 epochs\n",
    "# accuracy 61%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model with best parameters and different optimizer\n",
    "model = Sequential()\n",
    "model.add(Dense(2,input_dim = 13,activation = 'sigmoid'))\n",
    "model.add(Dense(5,activation = 'relu')) # added one more hidden layer\n",
    "model.add(Dense(1,activation = 'softmax'))\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 303 samples\n",
      "Epoch 1/250\n",
      "303/303 [==============================] - 0s 1ms/sample - loss: 0.7859 - accuracy: 0.5446\n",
      "Epoch 2/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7834 - accuracy: 0.5446\n",
      "Epoch 3/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7808 - accuracy: 0.5446\n",
      "Epoch 4/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.7785 - accuracy: 0.5446\n",
      "Epoch 5/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7763 - accuracy: 0.5446\n",
      "Epoch 6/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7743 - accuracy: 0.5446\n",
      "Epoch 7/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.7718 - accuracy: 0.5446\n",
      "Epoch 8/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.7696 - accuracy: 0.5446\n",
      "Epoch 9/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.7647 - accuracy: 0.5446\n",
      "Epoch 10/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.7510 - accuracy: 0.5446\n",
      "Epoch 11/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.7172 - accuracy: 0.5446\n",
      "Epoch 12/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6894 - accuracy: 0.5446\n",
      "Epoch 13/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6844 - accuracy: 0.5446\n",
      "Epoch 14/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6810 - accuracy: 0.5446\n",
      "Epoch 15/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6799 - accuracy: 0.5446\n",
      "Epoch 16/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6798 - accuracy: 0.5446\n",
      "Epoch 17/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6793 - accuracy: 0.5446\n",
      "Epoch 18/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6778 - accuracy: 0.5446\n",
      "Epoch 19/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6763 - accuracy: 0.5446\n",
      "Epoch 20/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6748 - accuracy: 0.5446\n",
      "Epoch 21/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6753 - accuracy: 0.5446\n",
      "Epoch 22/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6750 - accuracy: 0.5446\n",
      "Epoch 23/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6739 - accuracy: 0.5446\n",
      "Epoch 24/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6733 - accuracy: 0.5446\n",
      "Epoch 25/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6734 - accuracy: 0.5446\n",
      "Epoch 26/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6727 - accuracy: 0.5446\n",
      "Epoch 27/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6721 - accuracy: 0.5446\n",
      "Epoch 28/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6734 - accuracy: 0.5446\n",
      "Epoch 29/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6726 - accuracy: 0.5479\n",
      "Epoch 30/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6711 - accuracy: 0.6040\n",
      "Epoch 31/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6703 - accuracy: 0.6073\n",
      "Epoch 32/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6707 - accuracy: 0.6139\n",
      "Epoch 33/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6708 - accuracy: 0.6106\n",
      "Epoch 34/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6703 - accuracy: 0.6040\n",
      "Epoch 35/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6691 - accuracy: 0.6172\n",
      "Epoch 36/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6702 - accuracy: 0.6172\n",
      "Epoch 37/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6691 - accuracy: 0.6073\n",
      "Epoch 38/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6690 - accuracy: 0.5941\n",
      "Epoch 39/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6679 - accuracy: 0.6139\n",
      "Epoch 40/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6676 - accuracy: 0.6205\n",
      "Epoch 41/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6673 - accuracy: 0.6172\n",
      "Epoch 42/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6670 - accuracy: 0.6172\n",
      "Epoch 43/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6669 - accuracy: 0.6172\n",
      "Epoch 44/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6660 - accuracy: 0.6139\n",
      "Epoch 45/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6667 - accuracy: 0.6106\n",
      "Epoch 46/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6663 - accuracy: 0.6106\n",
      "Epoch 47/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6661 - accuracy: 0.6106\n",
      "Epoch 48/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6667 - accuracy: 0.5941\n",
      "Epoch 49/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6668 - accuracy: 0.5974\n",
      "Epoch 50/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6679 - accuracy: 0.5941\n",
      "Epoch 51/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6693 - accuracy: 0.5875\n",
      "Epoch 52/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6680 - accuracy: 0.5974\n",
      "Epoch 53/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6666 - accuracy: 0.6007\n",
      "Epoch 54/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6655 - accuracy: 0.6172\n",
      "Epoch 55/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6642 - accuracy: 0.6205\n",
      "Epoch 56/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6641 - accuracy: 0.6205\n",
      "Epoch 57/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6639 - accuracy: 0.6172\n",
      "Epoch 58/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6635 - accuracy: 0.6172\n",
      "Epoch 59/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6639 - accuracy: 0.6040\n",
      "Epoch 60/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6640 - accuracy: 0.5974\n",
      "Epoch 61/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6630 - accuracy: 0.6040\n",
      "Epoch 62/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6627 - accuracy: 0.6172\n",
      "Epoch 63/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6625 - accuracy: 0.6205\n",
      "Epoch 64/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6624 - accuracy: 0.6205\n",
      "Epoch 65/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6624 - accuracy: 0.6205\n",
      "Epoch 66/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6618 - accuracy: 0.6172\n",
      "Epoch 67/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6614 - accuracy: 0.6172\n",
      "Epoch 68/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6616 - accuracy: 0.6172\n",
      "Epoch 69/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6614 - accuracy: 0.6205\n",
      "Epoch 70/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6611 - accuracy: 0.6139\n",
      "Epoch 71/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6616 - accuracy: 0.6106\n",
      "Epoch 72/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6611 - accuracy: 0.6172\n",
      "Epoch 73/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6608 - accuracy: 0.6205\n",
      "Epoch 74/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6614 - accuracy: 0.6139\n",
      "Epoch 75/250\n",
      "303/303 [==============================] - 0s 53us/sample - loss: 0.6625 - accuracy: 0.6205\n",
      "Epoch 76/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6625 - accuracy: 0.6205\n",
      "Epoch 77/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6619 - accuracy: 0.6238\n",
      "Epoch 78/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6612 - accuracy: 0.6106\n",
      "Epoch 79/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6601 - accuracy: 0.6106\n",
      "Epoch 80/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6587 - accuracy: 0.6172\n",
      "Epoch 81/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6598 - accuracy: 0.6139\n",
      "Epoch 82/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6598 - accuracy: 0.6106\n",
      "Epoch 83/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6589 - accuracy: 0.6139\n",
      "Epoch 84/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6576 - accuracy: 0.6139\n",
      "Epoch 85/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6581 - accuracy: 0.6205\n",
      "Epoch 86/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6584 - accuracy: 0.6106\n",
      "Epoch 87/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6590 - accuracy: 0.6139\n",
      "Epoch 88/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6605 - accuracy: 0.6172\n",
      "Epoch 89/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6614 - accuracy: 0.6337\n",
      "Epoch 90/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6605 - accuracy: 0.6304\n",
      "Epoch 91/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6586 - accuracy: 0.6205\n",
      "Epoch 92/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6581 - accuracy: 0.6205\n",
      "Epoch 93/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6574 - accuracy: 0.6172\n",
      "Epoch 94/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6571 - accuracy: 0.6106\n",
      "Epoch 95/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6561 - accuracy: 0.6271\n",
      "Epoch 96/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6584 - accuracy: 0.6238\n",
      "Epoch 97/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6577 - accuracy: 0.6271\n",
      "Epoch 98/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6579 - accuracy: 0.6238\n",
      "Epoch 99/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6568 - accuracy: 0.6172\n",
      "Epoch 100/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6554 - accuracy: 0.6139\n",
      "Epoch 101/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6544 - accuracy: 0.6205\n",
      "Epoch 102/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6567 - accuracy: 0.6172\n",
      "Epoch 103/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6570 - accuracy: 0.6205\n",
      "Epoch 104/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6568 - accuracy: 0.6238\n",
      "Epoch 105/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6559 - accuracy: 0.6172\n",
      "Epoch 106/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6553 - accuracy: 0.6172\n",
      "Epoch 107/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6541 - accuracy: 0.6304\n",
      "Epoch 108/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6545 - accuracy: 0.6172\n",
      "Epoch 109/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6543 - accuracy: 0.6172\n",
      "Epoch 110/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6543 - accuracy: 0.6205\n",
      "Epoch 111/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6535 - accuracy: 0.6271\n",
      "Epoch 112/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6534 - accuracy: 0.6271\n",
      "Epoch 113/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6532 - accuracy: 0.6304\n",
      "Epoch 114/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6531 - accuracy: 0.6271\n",
      "Epoch 115/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6529 - accuracy: 0.6271\n",
      "Epoch 116/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6528 - accuracy: 0.6271\n",
      "Epoch 117/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6526 - accuracy: 0.6271\n",
      "Epoch 118/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6539 - accuracy: 0.6238\n",
      "Epoch 119/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6541 - accuracy: 0.6238\n",
      "Epoch 120/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6539 - accuracy: 0.6205\n",
      "Epoch 121/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6510 - accuracy: 0.6238\n",
      "Epoch 122/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6523 - accuracy: 0.6238\n",
      "Epoch 123/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6511 - accuracy: 0.6337\n",
      "Epoch 124/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6522 - accuracy: 0.6337\n",
      "Epoch 125/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6526 - accuracy: 0.6337\n",
      "Epoch 126/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6521 - accuracy: 0.6337\n",
      "Epoch 127/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6516 - accuracy: 0.6403\n",
      "Epoch 128/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6513 - accuracy: 0.6370\n",
      "Epoch 129/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6509 - accuracy: 0.6271\n",
      "Epoch 130/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6503 - accuracy: 0.6304\n",
      "Epoch 131/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6505 - accuracy: 0.6238\n",
      "Epoch 132/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6503 - accuracy: 0.6271\n",
      "Epoch 133/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6506 - accuracy: 0.6271\n",
      "Epoch 134/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6503 - accuracy: 0.6403\n",
      "Epoch 135/250\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.64 - 0s 43us/sample - loss: 0.6505 - accuracy: 0.6337\n",
      "Epoch 136/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6503 - accuracy: 0.6337\n",
      "Epoch 137/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6501 - accuracy: 0.6370\n",
      "Epoch 138/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6497 - accuracy: 0.6403\n",
      "Epoch 139/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6495 - accuracy: 0.6403\n",
      "Epoch 140/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6497 - accuracy: 0.6271\n",
      "Epoch 141/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6493 - accuracy: 0.6370\n",
      "Epoch 142/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6490 - accuracy: 0.6271\n",
      "Epoch 143/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6488 - accuracy: 0.6337\n",
      "Epoch 144/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6499 - accuracy: 0.6172\n",
      "Epoch 145/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6493 - accuracy: 0.6238\n",
      "Epoch 146/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6487 - accuracy: 0.6337\n",
      "Epoch 147/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6483 - accuracy: 0.6337\n",
      "Epoch 148/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6481 - accuracy: 0.6436\n",
      "Epoch 149/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6480 - accuracy: 0.6469\n",
      "Epoch 150/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6477 - accuracy: 0.6436\n",
      "Epoch 151/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6480 - accuracy: 0.6337\n",
      "Epoch 152/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6480 - accuracy: 0.6403\n",
      "Epoch 153/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6475 - accuracy: 0.6436\n",
      "Epoch 154/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6469 - accuracy: 0.6403\n",
      "Epoch 155/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6472 - accuracy: 0.6337\n",
      "Epoch 156/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6527 - accuracy: 0.6271\n",
      "Epoch 157/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6553 - accuracy: 0.6205\n",
      "Epoch 158/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6513 - accuracy: 0.6304\n",
      "Epoch 159/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6471 - accuracy: 0.6304\n",
      "Epoch 160/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6456 - accuracy: 0.6403\n",
      "Epoch 161/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6456 - accuracy: 0.6370\n",
      "Epoch 162/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6466 - accuracy: 0.6436\n",
      "Epoch 163/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6453 - accuracy: 0.6469\n",
      "Epoch 164/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6460 - accuracy: 0.6469\n",
      "Epoch 165/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6462 - accuracy: 0.6535\n",
      "Epoch 166/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6459 - accuracy: 0.6502\n",
      "Epoch 167/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6460 - accuracy: 0.6535\n",
      "Epoch 168/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6459 - accuracy: 0.6535\n",
      "Epoch 169/250\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6472 - accuracy: 0.6469\n",
      "Epoch 170/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6489 - accuracy: 0.6403\n",
      "Epoch 171/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6472 - accuracy: 0.6469\n",
      "Epoch 172/250\n",
      "303/303 [==============================] - 0s 30us/sample - loss: 0.6459 - accuracy: 0.6502\n",
      "Epoch 173/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6445 - accuracy: 0.6535\n",
      "Epoch 174/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6441 - accuracy: 0.6403\n",
      "Epoch 175/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6447 - accuracy: 0.6568\n",
      "Epoch 176/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6442 - accuracy: 0.6535\n",
      "Epoch 177/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6440 - accuracy: 0.6469\n",
      "Epoch 178/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6438 - accuracy: 0.6535\n",
      "Epoch 179/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6439 - accuracy: 0.6535\n",
      "Epoch 180/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6440 - accuracy: 0.6535\n",
      "Epoch 181/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6449 - accuracy: 0.6502\n",
      "Epoch 182/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6446 - accuracy: 0.6535\n",
      "Epoch 183/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6421 - accuracy: 0.6502\n",
      "Epoch 184/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6434 - accuracy: 0.6304\n",
      "Epoch 185/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6440 - accuracy: 0.6337\n",
      "Epoch 186/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6446 - accuracy: 0.6403\n",
      "Epoch 187/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6447 - accuracy: 0.6436\n",
      "Epoch 188/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6436 - accuracy: 0.6337\n",
      "Epoch 189/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6419 - accuracy: 0.6370\n",
      "Epoch 190/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6416 - accuracy: 0.6469\n",
      "Epoch 191/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6411 - accuracy: 0.6634\n",
      "Epoch 192/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6426 - accuracy: 0.6535\n",
      "Epoch 193/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6428 - accuracy: 0.6568\n",
      "Epoch 194/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6421 - accuracy: 0.6568\n",
      "Epoch 195/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6414 - accuracy: 0.6535\n",
      "Epoch 196/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6406 - accuracy: 0.6634\n",
      "Epoch 197/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6403 - accuracy: 0.6568\n",
      "Epoch 198/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6403 - accuracy: 0.6568\n",
      "Epoch 199/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6403 - accuracy: 0.6535\n",
      "Epoch 200/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6399 - accuracy: 0.6601\n",
      "Epoch 201/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6398 - accuracy: 0.6667\n",
      "Epoch 202/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6407 - accuracy: 0.6535\n",
      "Epoch 203/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6410 - accuracy: 0.6568\n",
      "Epoch 204/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6410 - accuracy: 0.6601\n",
      "Epoch 205/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6422 - accuracy: 0.6502\n",
      "Epoch 206/250\n",
      "303/303 [==============================] - 0s 49us/sample - loss: 0.6392 - accuracy: 0.6568\n",
      "Epoch 207/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6389 - accuracy: 0.6634\n",
      "Epoch 208/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6385 - accuracy: 0.6502\n",
      "Epoch 209/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6383 - accuracy: 0.6502\n",
      "Epoch 210/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6381 - accuracy: 0.6502\n",
      "Epoch 211/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6383 - accuracy: 0.6535\n",
      "Epoch 212/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6377 - accuracy: 0.6535\n",
      "Epoch 213/250\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.6382 - accuracy: 0.6634\n",
      "Epoch 214/250\n",
      "303/303 [==============================] - 0s 41us/sample - loss: 0.6379 - accuracy: 0.6667\n",
      "Epoch 215/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6378 - accuracy: 0.6667\n",
      "Epoch 216/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6367 - accuracy: 0.6700\n",
      "Epoch 217/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6363 - accuracy: 0.6535\n",
      "Epoch 218/250\n",
      "303/303 [==============================] - 0s 40us/sample - loss: 0.6366 - accuracy: 0.6502\n",
      "Epoch 219/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6368 - accuracy: 0.6634\n",
      "Epoch 220/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6363 - accuracy: 0.6700\n",
      "Epoch 221/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6370 - accuracy: 0.6700\n",
      "Epoch 222/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6371 - accuracy: 0.6568\n",
      "Epoch 223/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6378 - accuracy: 0.6601\n",
      "Epoch 224/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6371 - accuracy: 0.6601\n",
      "Epoch 225/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6357 - accuracy: 0.6667\n",
      "Epoch 226/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6352 - accuracy: 0.6634\n",
      "Epoch 227/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6347 - accuracy: 0.6469\n",
      "Epoch 228/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6353 - accuracy: 0.6502\n",
      "Epoch 229/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6353 - accuracy: 0.6535\n",
      "Epoch 230/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6345 - accuracy: 0.6535\n",
      "Epoch 231/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6335 - accuracy: 0.6634\n",
      "Epoch 232/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6346 - accuracy: 0.6700\n",
      "Epoch 233/250\n",
      "303/303 [==============================] - 0s 63us/sample - loss: 0.6355 - accuracy: 0.6667\n",
      "Epoch 234/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6367 - accuracy: 0.6502\n",
      "Epoch 235/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6382 - accuracy: 0.6403\n",
      "Epoch 236/250\n",
      "303/303 [==============================] - 0s 46us/sample - loss: 0.6409 - accuracy: 0.6403\n",
      "Epoch 237/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6386 - accuracy: 0.6370\n",
      "Epoch 238/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6355 - accuracy: 0.6601\n",
      "Epoch 239/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6324 - accuracy: 0.6799\n",
      "Epoch 240/250\n",
      "303/303 [==============================] - 0s 59us/sample - loss: 0.6319 - accuracy: 0.6667\n",
      "Epoch 241/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6330 - accuracy: 0.6469\n",
      "Epoch 242/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6306 - accuracy: 0.6667\n",
      "Epoch 243/250\n",
      "303/303 [==============================] - 0s 43us/sample - loss: 0.6309 - accuracy: 0.6799\n",
      "Epoch 244/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6311 - accuracy: 0.6832\n",
      "Epoch 245/250\n",
      "303/303 [==============================] - 0s 33us/sample - loss: 0.6306 - accuracy: 0.6766\n",
      "Epoch 246/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6303 - accuracy: 0.6700\n",
      "Epoch 247/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6294 - accuracy: 0.6799\n",
      "Epoch 248/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6326 - accuracy: 0.6601\n",
      "Epoch 249/250\n",
      "303/303 [==============================] - 0s 36us/sample - loss: 0.6355 - accuracy: 0.6403\n",
      "Epoch 250/250\n",
      "303/303 [==============================] - 0s 39us/sample - loss: 0.6346 - accuracy: 0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2094a4db710>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs = 250,batch_size = 50, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 66.66666865348816\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X,y,verbose = False)\n",
    "print(f\"{model.metrics_names[1]}: {score[1]*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After tuning hyperparameters, was able to get up to 66% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
